{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Reranking in RAG Systems with Gemini\n",
    "\n",
    "This notebook demonstrates how to implement semantic reranking in a Retrieval-Augmented Generation (RAG) system using:\n",
    "- **Sentence Transformers** for semantic similarity\n",
    "- **FAISS** for efficient vector search\n",
    "- **Google Gemini** for intelligent explanations and final answer generation\n",
    "\n",
    "## Project Overview\n",
    "We'll build a question-answering system about space exploration that:\n",
    "1. Retrieves relevant documents using vector search\n",
    "2. Reranks results using semantic similarity\n",
    "3. Uses Gemini to provide comprehensive answers with explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (4.1.0)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.11.0-cp310-cp310-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "Requirement already satisfied: numpy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: google-generativeai in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: scikit-learn in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: tqdm in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scipy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: packaging in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: google-api-python-client in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-generativeai) (2.173.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: google-api-core in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: pydantic in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.11.0->sentence-transformers) (58.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/chunking/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers faiss-cpu numpy pandas google-generativeai python-dotenv scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import google.generativeai as genai\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini API configured!\n"
     ]
    }
   ],
   "source": [
    "# Configure Gemini API\n",
    "# You'll need to get your API key from https://makersuite.google.com/app/apikey\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY') or 'your-gemini-api-key-here'\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Initialize Gemini model\n",
    "gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "print(\"✅ Gemini API configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Dataset: Space Exploration Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Created knowledge base with 8 documents\n",
      "Sample document:\n",
      "Title: Mars Exploration Overview\n",
      "Content: Mars exploration has been a key focus of space agencies worldwide. NASA's Mars rovers, including Per...\n"
     ]
    }
   ],
   "source": [
    "# Create a sample knowledge base about space exploration\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"title\": \"Mars Exploration Overview\",\n",
    "        \"content\": \"Mars exploration has been a key focus of space agencies worldwide. NASA's Mars rovers, including Perseverance and Curiosity, have provided invaluable data about the Red Planet's geology, climate, and potential for past life. The planet's thin atmosphere, composed mainly of carbon dioxide, presents unique challenges for exploration missions.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"title\": \"International Space Station Operations\",\n",
    "        \"content\": \"The International Space Station (ISS) serves as a microgravity laboratory where astronauts conduct scientific experiments. Located approximately 408 kilometers above Earth, the ISS completes an orbit around our planet every 90 minutes. The station supports research in biology, physics, astronomy, and materials science.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"title\": \"Lunar Mission History\",\n",
    "        \"content\": \"The Apollo program achieved the historic goal of landing humans on the Moon between 1969 and 1972. Six successful Moon landings were completed, with Apollo 11 being the first. Neil Armstrong and Buzz Aldrin were the first humans to walk on the lunar surface, while Michael Collins orbited above in the command module.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"title\": \"Exoplanet Discovery Methods\",\n",
    "        \"content\": \"Astronomers use various methods to discover exoplanets, including the transit method and radial velocity method. The Kepler Space Telescope and TESS have identified thousands of potential exoplanets. Many of these worlds orbit in their star's habitable zone, where liquid water could potentially exist.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"title\": \"SpaceX Rocket Technology\",\n",
    "        \"content\": \"SpaceX has revolutionized space travel with reusable rocket technology. The Falcon 9 rocket can land its first stage back on Earth, significantly reducing launch costs. The company's Starship project aims to enable human missions to Mars and establish a sustainable presence on the Red Planet.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"title\": \"Jupiter's Moons Exploration\",\n",
    "        \"content\": \"Jupiter's largest moons - Io, Europa, Ganymede, and Callisto - are fascinating targets for exploration. Europa is particularly interesting due to its subsurface ocean beneath an icy crust, making it a prime candidate for the search for extraterrestrial life. NASA's Europa Clipper mission will study this moon in detail.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 7,\n",
    "        \"title\": \"Solar System Formation\",\n",
    "        \"content\": \"The solar system formed approximately 4.6 billion years ago from a collapsing cloud of gas and dust called the solar nebula. The Sun formed at the center, while planets formed from the remaining material in the protoplanetary disk. Inner planets are rocky, while outer planets are gas giants.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 8,\n",
    "        \"title\": \"Space Telescopes and Observations\",\n",
    "        \"content\": \"Space telescopes like Hubble, Spitzer, and James Webb provide unprecedented views of the universe. These instruments observe in different wavelengths of light, from visible to infrared, revealing details about star formation, galaxy evolution, and the early universe that ground-based telescopes cannot achieve.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"📚 Created knowledge base with {len(documents)} documents\")\n",
    "print(\"Sample document:\")\n",
    "print(f\"Title: {documents[0]['title']}\")\n",
    "print(f\"Content: {documents[0]['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Semantic Reranking System Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SemanticReranker class defined!\n"
     ]
    }
   ],
   "source": [
    "class SemanticReranker:\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the semantic reranker with a sentence transformer model.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name of the sentence transformer model to use\n",
    "        \"\"\"\n",
    "        print(f\"🔄 Loading sentence transformer model: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.embeddings = None\n",
    "        self.index = None\n",
    "        self.documents = None\n",
    "        \n",
    "    def build_index(self, documents: List[Dict]):\n",
    "        \"\"\"\n",
    "        Build FAISS index from documents.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of document dictionaries\n",
    "        \"\"\"\n",
    "        print(\"🔧 Building document embeddings and FAISS index...\")\n",
    "        self.documents = documents\n",
    "        \n",
    "        # Combine title and content for better semantic representation\n",
    "        texts = [f\"{doc['title']}. {doc['content']}\" for doc in documents]\n",
    "        \n",
    "        # Generate embeddings\n",
    "        self.embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        \n",
    "        # Build FAISS index\n",
    "        dimension = self.embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity\n",
    "        normalized_embeddings = self.embeddings / np.linalg.norm(self.embeddings, axis=1, keepdims=True)\n",
    "        self.index.add(normalized_embeddings.astype('float32'))\n",
    "        \n",
    "        print(f\"✅ Index built with {len(documents)} documents (dimension: {dimension})\")\n",
    "    \n",
    "    def initial_retrieval(self, query: str, k: int = 10) -> List[Tuple[Dict, float]]:\n",
    "        \"\"\"\n",
    "        Perform initial retrieval using FAISS.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of documents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of (document, score) tuples\n",
    "        \"\"\"\n",
    "        # Encode query\n",
    "        query_embedding = self.model.encode([query])\n",
    "        query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "        \n",
    "        # Search\n",
    "        scores, indices = self.index.search(query_embedding.astype('float32'), k)\n",
    "        \n",
    "        # Return documents with scores\n",
    "        results = []\n",
    "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "            if idx != -1:  # Valid index\n",
    "                results.append((self.documents[idx], float(score)))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def semantic_rerank(self, query: str, retrieved_docs: List[Tuple[Dict, float]], \n",
    "                       top_k: int = 5) -> List[Tuple[Dict, float, float]]:\n",
    "        \"\"\"\n",
    "        Rerank retrieved documents using semantic similarity.\n",
    "        \n",
    "        Args:\n",
    "            query: Original search query\n",
    "            retrieved_docs: List of (document, initial_score) tuples\n",
    "            top_k: Number of top documents to return after reranking\n",
    "            \n",
    "        Returns:\n",
    "            List of (document, initial_score, rerank_score) tuples\n",
    "        \"\"\"\n",
    "        if not retrieved_docs:\n",
    "            return []\n",
    "        \n",
    "        # Encode query\n",
    "        query_embedding = self.model.encode([query])\n",
    "        \n",
    "        # Encode retrieved documents\n",
    "        doc_texts = [f\"{doc['title']}. {doc['content']}\" for doc, _ in retrieved_docs]\n",
    "        doc_embeddings = self.model.encode(doc_texts)\n",
    "        \n",
    "        # Compute semantic similarity scores\n",
    "        similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "        \n",
    "        # Combine with original documents and scores\n",
    "        reranked_results = []\n",
    "        for i, (doc, initial_score) in enumerate(retrieved_docs):\n",
    "            rerank_score = similarities[i]\n",
    "            reranked_results.append((doc, initial_score, rerank_score))\n",
    "        \n",
    "        # Sort by rerank score (descending)\n",
    "        reranked_results.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        return reranked_results[:top_k]\n",
    "\n",
    "print(\"✅ SemanticReranker class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG System with Gemini Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAGSystem class defined!\n"
     ]
    }
   ],
   "source": [
    "class RAGSystem:\n",
    "    def __init__(self, reranker: SemanticReranker, gemini_model):\n",
    "        self.reranker = reranker\n",
    "        self.gemini_model = gemini_model\n",
    "    \n",
    "    def generate_answer_with_explanation(self, query: str, context_docs: List[Dict]) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate answer using Gemini with retrieved context.\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            context_docs: List of relevant documents\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing answer and explanation\n",
    "        \"\"\"\n",
    "        # Prepare context\n",
    "        context_text = \"\\n\\n\".join([\n",
    "            f\"Document {i+1}: {doc['title']}\\n{doc['content']}\"\n",
    "            for i, doc in enumerate(context_docs)\n",
    "        ])\n",
    "        \n",
    "        # Create prompt for Gemini\n",
    "        prompt = f\"\"\"\n",
    "You are an expert space exploration assistant. Based on the provided context documents, answer the user's question comprehensively.\n",
    "\n",
    "Context Documents:\n",
    "{context_text}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Please provide:\n",
    "1. A direct answer to the question\n",
    "2. An explanation of how you arrived at this answer\n",
    "3. Which specific documents were most relevant and why\n",
    "4. Any additional insights or related information that might be helpful\n",
    "\n",
    "Format your response as:\n",
    "**Answer:** [Your direct answer]\n",
    "\n",
    "**Explanation:** [How you derived the answer from the context]\n",
    "\n",
    "**Most Relevant Sources:** [Which documents were key and why]\n",
    "\n",
    "**Additional Insights:** [Any related information or connections]\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.gemini_model.generate_content(prompt)\n",
    "            return {\n",
    "                'answer': response.text,\n",
    "                'context_docs': context_docs,\n",
    "                'query': query\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'answer': f\"Error generating response: {str(e)}\",\n",
    "                'context_docs': context_docs,\n",
    "                'query': query\n",
    "            }\n",
    "    \n",
    "    def process_query(self, query: str, retrieve_k: int = 8, rerank_k: int = 3) -> Dict:\n",
    "        \"\"\"\n",
    "        Complete RAG pipeline: retrieve, rerank, generate.\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            retrieve_k: Number of documents to initially retrieve\n",
    "            rerank_k: Number of documents to keep after reranking\n",
    "            \n",
    "        Returns:\n",
    "            Complete response with answer, scores, and metadata\n",
    "        \"\"\"\n",
    "        print(f\"🔍 Processing query: '{query}'\")\n",
    "        \n",
    "        # Step 1: Initial retrieval\n",
    "        print(f\"📥 Retrieving top {retrieve_k} documents...\")\n",
    "        retrieved_docs = self.reranker.initial_retrieval(query, k=retrieve_k)\n",
    "        \n",
    "        # Step 2: Semantic reranking\n",
    "        print(f\"📊 Reranking to top {rerank_k} documents...\")\n",
    "        reranked_docs = self.reranker.semantic_rerank(query, retrieved_docs, top_k=rerank_k)\n",
    "        \n",
    "        # Extract just the documents for context\n",
    "        context_docs = [doc for doc, _, _ in reranked_docs]\n",
    "        \n",
    "        # Step 3: Generate answer with Gemini\n",
    "        print(\"🤖 Generating answer with Gemini...\")\n",
    "        result = self.generate_answer_with_explanation(query, context_docs)\n",
    "        \n",
    "        # Add retrieval and ranking information\n",
    "        result['retrieval_info'] = {\n",
    "            'initial_retrieval_count': len(retrieved_docs),\n",
    "            'reranked_docs': [{\n",
    "                'title': doc['title'],\n",
    "                'initial_score': initial_score,\n",
    "                'rerank_score': rerank_score\n",
    "            } for doc, initial_score, rerank_score in reranked_docs]\n",
    "        }\n",
    "        \n",
    "        print(\"✅ Query processing complete!\")\n",
    "        return result\n",
    "\n",
    "print(\"✅ RAGSystem class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize and Build the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading sentence transformer model: all-MiniLM-L6-v2\n",
      "🔧 Building document embeddings and FAISS index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████| 1/1 [00:00<00:00, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Index built with 8 documents (dimension: 384)\n",
      "🚀 RAG System initialized and ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the semantic reranker\n",
    "reranker = SemanticReranker()\n",
    "\n",
    "# Build the index with our documents\n",
    "reranker.build_index(documents)\n",
    "\n",
    "# Initialize the complete RAG system\n",
    "rag_system = RAGSystem(reranker, gemini_model)\n",
    "\n",
    "print(\"🚀 RAG System initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demo: Testing the Semantic Reranking System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Processing query: 'What do we know about life on Mars?'\n",
      "📥 Retrieving top 6 documents...\n",
      "📊 Reranking to top 3 documents...\n",
      "🤖 Generating answer with Gemini...\n",
      "✅ Query processing complete!\n",
      "================================================================================\n",
      "🔍 QUERY: What do we know about life on Mars?\n",
      "================================================================================\n",
      "\n",
      "📊 RETRIEVAL & RANKING SCORES:\n",
      "1. Mars Exploration Overview\n",
      "   Initial Score: 0.5849\n",
      "   Rerank Score:  0.5849\n",
      "\n",
      "2. Exoplanet Discovery Methods\n",
      "   Initial Score: 0.3117\n",
      "   Rerank Score:  0.3117\n",
      "\n",
      "3. Jupiter's Moons Exploration\n",
      "   Initial Score: 0.3106\n",
      "   Rerank Score:  0.3106\n",
      "\n",
      "\n",
      "🤖 GEMINI RESPONSE:\n",
      "--------------------------------------------------\n",
      "**Answer:**  Currently, we have no definitive proof of past or present life on Mars. However, evidence gathered by rovers like Perseverance and Curiosity suggests the possibility of past habitable conditions, including the presence of liquid water.\n",
      "\n",
      "**Explanation:** The provided text focuses on the exploration of Mars and other celestial bodies, not on conclusive findings regarding Martian life. Document 1 mentions that NASA rovers have gathered data about Mars' geology, climate, and *potential* for past life.  The key word here is \"potential.\"  The documents do not state that life has been found, only that conditions *may* have been suitable for life at some point in Mars' history.  The absence of explicit statements about confirmed life on Mars is significant.\n",
      "\n",
      "**Most Relevant Sources:** Document 1 (Mars Exploration Overview) is the most relevant because it directly addresses Mars exploration and mentions the search for evidence of past life. While other documents discuss other celestial bodies with potential for life (Europa), they are not directly relevant to the question of life *on Mars*.\n",
      "\n",
      "**Additional Insights:**  The search for life on Mars is an ongoing process.  The discovery of organic molecules and evidence of past water on Mars are considered significant steps in this search. However, finding conclusive evidence of past or present life remains a major scientific goal.  Further missions and advanced technologies are needed to answer this question definitively. The focus is shifting from simply searching for evidence of past habitability to actively looking for biosignatures – indicators of past or present life – in Martian rocks and soil.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test queries to demonstrate the system\n",
    "test_queries = [\n",
    "    \"What do we know about life on Mars?\",\n",
    "    \"How do space telescopes help us understand the universe?\",\n",
    "    \"What makes Europa interesting for astrobiology?\"\n",
    "]\n",
    "\n",
    "def display_results(result: Dict):\n",
    "    \"\"\"\n",
    "    Display results in a formatted way.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"🔍 QUERY: {result['query']}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show retrieval information\n",
    "    print(\"\\n📊 RETRIEVAL & RANKING SCORES:\")\n",
    "    for i, doc_info in enumerate(result['retrieval_info']['reranked_docs']):\n",
    "        print(f\"{i+1}. {doc_info['title']}\")\n",
    "        print(f\"   Initial Score: {doc_info['initial_score']:.4f}\")\n",
    "        print(f\"   Rerank Score:  {doc_info['rerank_score']:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    # Show Gemini's response\n",
    "    print(\"\\n🤖 GEMINI RESPONSE:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(result['answer'])\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Run demo with first query\n",
    "demo_query = test_queries[0]\n",
    "result = rag_system.process_query(demo_query, retrieve_k=6, rerank_k=3)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison: Before and After Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Comparing ranking methods for: 'What do we know about life on Mars?'\n",
      "\n",
      "📥 INITIAL RETRIEVAL (FAISS):\n",
      "----------------------------------------\n",
      "1. Mars Exploration Overview (Score: 0.5849)\n",
      "2. Exoplanet Discovery Methods (Score: 0.3117)\n",
      "3. Jupiter's Moons Exploration (Score: 0.3106)\n",
      "4. Space Telescopes and Observations (Score: 0.2669)\n",
      "5. Solar System Formation (Score: 0.2579)\n",
      "\n",
      "📊 AFTER SEMANTIC RERANKING:\n",
      "----------------------------------------\n",
      "1. Mars Exploration Overview\n",
      "   Initial: 0.5849 → Rerank: 0.5849\n",
      "2. Exoplanet Discovery Methods\n",
      "   Initial: 0.3117 → Rerank: 0.3117\n",
      "3. Jupiter's Moons Exploration\n",
      "   Initial: 0.3106 → Rerank: 0.3106\n",
      "4. Space Telescopes and Observations\n",
      "   Initial: 0.2669 → Rerank: 0.2669\n",
      "5. Solar System Formation\n",
      "   Initial: 0.2579 → Rerank: 0.2579\n",
      "\n",
      "➡️  Ranking remained the same.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 Comparing ranking methods for: 'How do space telescopes help us understand the universe?'\n",
      "\n",
      "📥 INITIAL RETRIEVAL (FAISS):\n",
      "----------------------------------------\n",
      "1. Space Telescopes and Observations (Score: 0.7319)\n",
      "2. Exoplanet Discovery Methods (Score: 0.3148)\n",
      "3. Mars Exploration Overview (Score: 0.2803)\n",
      "4. International Space Station Operations (Score: 0.2205)\n",
      "5. Jupiter's Moons Exploration (Score: 0.2155)\n",
      "\n",
      "📊 AFTER SEMANTIC RERANKING:\n",
      "----------------------------------------\n",
      "1. Space Telescopes and Observations\n",
      "   Initial: 0.7319 → Rerank: 0.7319\n",
      "2. Exoplanet Discovery Methods\n",
      "   Initial: 0.3148 → Rerank: 0.3148\n",
      "3. Mars Exploration Overview\n",
      "   Initial: 0.2803 → Rerank: 0.2803\n",
      "4. International Space Station Operations\n",
      "   Initial: 0.2205 → Rerank: 0.2205\n",
      "5. Jupiter's Moons Exploration\n",
      "   Initial: 0.2155 → Rerank: 0.2155\n",
      "\n",
      "➡️  Ranking remained the same.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_ranking_methods(query: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    Compare initial retrieval vs semantic reranking.\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Comparing ranking methods for: '{query}'\\n\")\n",
    "    \n",
    "    # Get initial retrieval results\n",
    "    initial_results = reranker.initial_retrieval(query, k=k)\n",
    "    \n",
    "    # Get reranked results\n",
    "    reranked_results = reranker.semantic_rerank(query, initial_results, top_k=k)\n",
    "    \n",
    "    # Display comparison\n",
    "    print(\"📥 INITIAL RETRIEVAL (FAISS):\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (doc, score) in enumerate(initial_results):\n",
    "        print(f\"{i+1}. {doc['title']} (Score: {score:.4f})\")\n",
    "    \n",
    "    print(\"\\n📊 AFTER SEMANTIC RERANKING:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (doc, initial_score, rerank_score) in enumerate(reranked_results):\n",
    "        print(f\"{i+1}. {doc['title']}\")\n",
    "        print(f\"   Initial: {initial_score:.4f} → Rerank: {rerank_score:.4f}\")\n",
    "    \n",
    "    # Show if ranking changed\n",
    "    initial_titles = [doc['title'] for doc, _ in initial_results[:k]]\n",
    "    reranked_titles = [doc['title'] for doc, _, _ in reranked_results[:k]]\n",
    "    \n",
    "    if initial_titles != reranked_titles:\n",
    "        print(\"\\n✨ RANKING CHANGED! Semantic reranking improved relevance.\")\n",
    "    else:\n",
    "        print(\"\\n➡️  Ranking remained the same.\")\n",
    "\n",
    "# Compare for different queries\n",
    "for query in test_queries[:2]:\n",
    "    compare_ranking_methods(query)\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interactive Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query():\n",
    "    \"\"\"\n",
    "    Interactive interface for testing queries.\n",
    "    \"\"\"\n",
    "    print(\"🚀 Interactive RAG System with Semantic Reranking\")\n",
    "    print(\"Ask questions about space exploration!\")\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"🔍 Your question: \").strip()\n",
    "            \n",
    "            if query.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"👋 Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            if not query:\n",
    "                continue\n",
    "            \n",
    "            # Process the query\n",
    "            result = rag_system.process_query(query, retrieve_k=6, rerank_k=3)\n",
    "            display_results(result)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n👋 Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "\n",
    "# Uncomment the next line to run the interactive interface\n",
    "# interactive_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performance Analysis and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "\n",
    "def analyze_performance(queries: List[str]):\n",
    "    \"\"\"\n",
    "    Analyze the performance of the RAG system.\n",
    "    \"\"\"\n",
    "    print(\"📊 PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_time = 0\n",
    "    retrieval_times = []\n",
    "    reranking_times = []\n",
    "    generation_times = []\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\nProcessing query {i+1}/{len(queries)}: '{query[:50]}...'\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Measure retrieval time\n",
    "        retrieval_start = time.time()\n",
    "        retrieved_docs = reranker.initial_retrieval(query, k=8)\n",
    "        retrieval_time = time.time() - retrieval_start\n",
    "        retrieval_times.append(retrieval_time)\n",
    "        \n",
    "        # Measure reranking time\n",
    "        reranking_start = time.time()\n",
    "        reranked_docs = reranker.semantic_rerank(query, retrieved_docs, top_k=3)\n",
    "        reranking_time = time.time() - reranking_start\n",
    "        reranking_times.append(reranking_time)\n",
    "        \n",
    "        # Measure generation time\n",
    "        generation_start = time.time()\n",
    "        context_docs = [doc for doc, _, _ in reranked_docs]\n",
    "        result = rag_system.generate_answer_with_explanation(query, context_docs)\n",
    "        generation_time = time.time() - generation_start\n",
    "        generation_times.append(generation_time)\n",
    "        \n",
    "        query_time = time.time() - start_time\n",
    "        total_time += query_time\n",
    "        \n",
    "        print(f\"  Retrieval: {retrieval_time:.3f}s\")\n",
    "        print(f\"  Reranking: {reranking_time:.3f}s\")\n",
    "        print(f\"  Generation: {generation_time:.3f}s\")\n",
    "        print(f\"  Total: {query_time:.3f}s\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n📈 SUMMARY STATISTICS\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total queries processed: {len(queries)}\")\n",
    "    print(f\"Average retrieval time: {np.mean(retrieval_times):.3f}s\")\n",
    "    print(f\"Average reranking time: {np.mean(reranking_times):.3f}s\")\n",
    "    print(f\"Average generation time: {np.mean(generation_times):.3f}s\")\n",
    "    print(f\"Average total time per query: {total_time/len(queries):.3f}s\")\n",
    "    print(f\"Total processing time: {total_time:.3f}s\")\n",
    "    \n",
    "    return {\n",
    "        'retrieval_times': retrieval_times,\n",
    "        'reranking_times': reranking_times,\n",
    "        'generation_times': generation_times,\n",
    "        'total_time': total_time\n",
    "    }\n",
    "\n",
    "# Run performance analysis\n",
    "performance_data = analyze_performance(test_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Takeaways and Next Steps\n",
    "\n",
    "### What We've Accomplished:\n",
    "\n",
    "1. **Semantic Reranking Implementation**: Built a complete semantic reranking system using sentence transformers and FAISS for efficient vector search.\n",
    "\n",
    "2. **RAG Pipeline**: Created an end-to-end RAG system that combines retrieval, reranking, and generation using Google Gemini.\n",
    "\n",
    "3. **Performance Analysis**: Demonstrated how semantic reranking can improve relevance compared to basic vector search.\n",
    "\n",
    "### Key Benefits of Semantic Reranking:\n",
    "\n",
    "- **Improved Relevance**: Goes beyond simple keyword matching to understand semantic meaning\n",
    "- **Context Awareness**: Better understanding of query intent and document relevance\n",
    "- **Quality Control**: Ensures the most relevant documents are used for answer generation\n",
    "\n",
    "### Potential Improvements:\n",
    "\n",
    "1. **Cross-Encoder Reranking**: Use more sophisticated reranking models like cross-encoders\n",
    "2. **Hybrid Scoring**: Combine multiple signals (semantic, lexical, metadata)\n",
    "3. **Query Analysis**: Different reranking strategies for different query types\n",
    "4. **Feedback Loop**: Learn from user interactions to improve ranking\n",
    "5. **Caching**: Cache embeddings and results for better performance\n",
    "\n",
    "### Production Considerations:\n",
    "\n",
    "- **Scalability**: Use more efficient vector databases like Pinecone or Weaviate\n",
    "- **Model Selection**: Choose appropriate embedding models for your domain\n",
    "- **Monitoring**: Track ranking quality and user satisfaction\n",
    "- **Cost Optimization**: Balance quality vs computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final demonstration with a complex query\n",
    "complex_query = \"Compare the exploration strategies for Mars and Europa, focusing on the search for life\"\n",
    "\n",
    "print(\"🎯 FINAL DEMONSTRATION: Complex Query\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_result = rag_system.process_query(complex_query, retrieve_k=8, rerank_k=4)\n",
    "display_results(final_result)\n",
    "\n",
    "print(\"🎉 Semantic Reranking RAG System Demo Complete!\")\n",
    "print(\"\\nThis notebook demonstrated:\")\n",
    "print(\"✅ Document embedding and indexing\")\n",
    "print(\"✅ Semantic similarity-based reranking\")\n",
    "print(\"✅ Integration with Gemini for explanations\")\n",
    "print(\"✅ Performance analysis and comparison\")\n",
    "print(\"✅ Complete RAG pipeline implementation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
